# --------------------------------------------------------------------------
# Three-Tier Metric System Configuration for Baseline SegFormer
# This configuration demonstrates the advanced metric evaluation architecture
# --------------------------------------------------------------------------

model:
  # This flag tells the factory to build the BaselineSegformer.
  type: "SegFormerBaseline"
  params:
    # Name of the SegFormer backbone.
    backbone: "nvidia/mit-b2"
    # Unified channel dimension for the standard MLP decoder.
    decoder_channel: 256
    # For a simple baseline, the number of output classes is specified directly.
    num_classes: 40

# --------------------------------------------------------------------------
# Configuration for Datasets and DataLoaders
# --------------------------------------------------------------------------
data:
  # The factory will first check if this is a valid local path. If not, it assumes
  # it's a Hugging Face Hub dataset ID.
  dataset_name: "EPFL-ECEO/coralscapes"

  # Path to the pre-processed PDS-sampled training patches.
  # This is prioritized for the 'train' split, as specified in dataset.py.
  pds_train_path: "./dataset/processed/pds_patches/"
  
  # Path to the raw, full-image dataset. Used for 'val' and 'test' splits,
  # and as a fallback for 'train' if pds_train_path is not found.
  data_root_path: "./dataset/"

  # The single source of truth for all class and task information.
  # Required for MTL models and for non-MTL models being evaluated on MTL tasks.
  task_definitions_path: "configs/task_definitions.yaml"
  
  # Parameters for the final DataLoader object.
  batch_size: 4
  num_workers: 4
  
  # A fundamental parameter shared by datasets and augmentations.
  patch_size: 512

# --------------------------------------------------------------------------
# Tier 1 (GPU-based fast metrics) Configuration
# --------------------------------------------------------------------------
metrics:
  # This list is crucial. It tells both metrics calculators which tasks should
  # be used to compute the Boundary IoU (BIoU) and the final H-Mean score.
  # The names must match the task names in task_definitions.yaml.
  primary_tasks: ["genus", "health"]
  
  # The thickness of the band (in pixels) used for BIoU calculation.
  boundary_thickness: 2
  
  # The class index to be ignored during metric calculation.
  # This should be consistent with the ignore_index in the loss function.
  ignore_index: 0

# --------------------------------------------------------------------------
# Tier 2/3 (CPU-based advanced metrics) Configuration
# --------------------------------------------------------------------------
metrics_processor:
  # Master switch to enable/disable the advanced metrics processing
  enabled: true
  
  # Number of CPU worker processes for parallel computation
  # Recommend: Number of physical CPU cores (e.g., 30+ for high-end systems)
  num_cpu_workers: 30
  
  # List of advanced metrics to compute
  # Available: ["ASSD", "HD95", "PanopticQuality", "ARI", "VI"]
  tasks:
    - "ASSD"           # Average Symmetric Surface Distance
    - "HD95"           # 95th percentile Hausdorff Distance
    - "PanopticQuality" # Panoptic Quality (PQ, SQ, RQ)
    - "ARI"            # Adjusted Rand Index
    - "VI"             # Variation of Information

# --------------------------------------------------------------------------
# The trainer section is needed to calculate total training steps for the scheduler.
# --------------------------------------------------------------------------
trainer:
  epochs: 100
  
  # Model selection metric - choose from Tier 1 metrics for fast evaluation
  # Available Tier 1 metrics:
  # - global.mIoU, global.BIoU, global.Boundary_F1
  # - global.NLL, global.Brier_Score, global.ECE
  # - global.classification_error, global.background_error, global.missed_error
  # - tasks.{task}.{level}.mIoU, tasks.{task}.{level}.BIoU
  model_selection_metric: "global.BIoU"
  
  # Output directory for all results
  output_dir: "experiments/three_tier_baseline"
  
  # Training device
  device: "cuda"
  
  # Mixed precision training
  use_mixed_precision: true
  
  # Learning rate and optimization
  learning_rate: 1e-4
  weight_decay: 1e-4
  
  # Validation scheduling (to save time during training)
  validation_frequency: 2  # Every 2 epochs after initial epochs

# --------------------------------------------------------------------------
# Evaluator Configuration
# --------------------------------------------------------------------------
evaluator:
  # Override checkpoint path if needed (default: uses trainer.output_dir/best_model.pth)
  # checkpoint_path: "path/to/specific/model.pth"
  
  # Override evaluation output directory if needed
  # output_dir: "evaluation_results/"
  
  # Inference parameters
  inference_stride: 256
  inference_batch_size: 8

# --------------------------------------------------------------------------
# Three-Tier System Workflow Summary:
#
# During Training:
# 1. Tier 1: GPU computes mIoU, BIoU, ECE, NLL, Brier, TIDE errors for model selection
# 2. Tier 2: CPU workers compute ASSD, HD95, PQ, ARI, VI in background (if enabled)
# 3. Tier 3: Dedicated I/O process writes advanced metrics to advanced_metrics.jsonl
#
# During Evaluation:
# 1. Same as training but with store_per_image=True for comprehensive analysis
# 2. Two output files:
#    - test_metrics_full_report.json (Tier 1 - fast metrics)
#    - advanced_metrics.jsonl (Tier 2 - per-image advanced metrics)
#
# Benefits:
# - GPU stays 100% focused on neural network computation
# - 30+ CPU cores handle complex metrics in parallel
# - Non-blocking dispatch ensures no training slowdown
# - Scalable: more CPU cores = faster metric computation
# - Comprehensive: both real-time and offline analysis metrics
# --------------------------------------------------------------------------