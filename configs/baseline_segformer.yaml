# --------------------------------------------------------------------------
model:
  # This flag tells the factory to build the BaselineSegformer.
  type: "SegFormerBaseline"
  params:
    # Name of the SegFormer backbone.
    backbone: "nvidia/mit-b2"
    # Unified channel dimension for the standard MLP decoder.
    decoder_channel: 256
    # For a simple baseline, the number of output classes is specified directly.
    num_classes: 40

# --------------------------------------------------------------------------
# Configuration for Datasets and DataLoaders
# --------------------------------------------------------------------------
data:
  # The factory will first check if this is a valid local path. If not, it assumes
  # it's a Hugging Face Hub dataset ID.
  dataset_name: "EPFL-ECEO/coralscapes"

  # Path to the pre-processed PDS-sampled training patches.
  # This is prioritized for the 'train' split, as specified in dataset.py.
  pds_train_path: "./dataset/processed/pds_patches/"
  
  # Path to the raw, full-image dataset. Used for 'val' and 'test' splits,
  # and as a fallback for 'train' if pds_train_path is not found.
  data_root_path: "./dataset/"

  # The single source of truth for all class and task information.
  # Required for MTL models and for non-MTL models being evaluated on MTL tasks.
  task_definitions_path: "configs/task_definitions.yaml"
  
  # Parameters for the final DataLoader object.
  batch_size: 4
  num_workers: 4
  
  # A fundamental parameter shared by datasets and augmentations.
  patch_size: 512

# --------------------------------------------------------------------------
metrics:
  # This list is crucial. It tells both metrics calculators which tasks should
  # be used to compute the Boundary IoU (BIoU) and the final H-Mean score.
  # The names must match the task names in task_definitions.yaml.
  primary_tasks: ["genus", "health"]
  
  # The thickness of the band (in pixels) used for BIoU calculation.
  boundary_thickness: 2
  
  # The class index to be ignored during metric calculation.
  # This should be consistent with the ignore_index in the loss function.
  ignore_index: 0


# --------------------------------------------------------------------------
# The trainer section is needed to calculate total training steps for the scheduler.
# --------------------------------------------------------------------------
trainer:
  epochs: 100